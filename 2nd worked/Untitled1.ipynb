{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oMV-4k0xvGP",
        "outputId": "0d45bd2f-1b5b-45c8-ef6d-a33eb3693dcd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "qSJAJT5SwrMi",
        "outputId": "01fe08c9-1f38-4e5b-9b97-6000914d7cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b1f1af6cacf6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load the model and TF-IDF vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf_vectorizer.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pkl'"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import fitz  # PyMuPDF\n",
        "import numpy as np\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Load the model and TF-IDF vectorizer\n",
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "tfidf_vectorizer = pickle.load(open('tfidf_vectorizer.pkl', 'rb'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocess input text by removing punctuation, converting to lowercase, and removing stopwords.\"\"\"\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    text = text.lower()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    text = \" \".join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n",
        "\n",
        "def detect(input_text):\n",
        "    \"\"\"Detect plagiarism in the given input text.\"\"\"\n",
        "    input_text = preprocess_text(input_text)\n",
        "    vectorized_text = tfidf_vectorizer.transform([input_text])\n",
        "    result = model.predict(vectorized_text)\n",
        "    return \"Plagiarism Detected\" if result[0] == 1 else \"No Plagiarism\"\n",
        "\n",
        "# Function to extract text from a PDF file using PyMuPDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Function to extract text from an image using Tesseract OCR\n",
        "def extract_text_from_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    return text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example: Process text input\n",
        "    input_text = \"\"\"Machine learning teaches computers to recognize patterns and make decisions automatically using data and algorithms. It can be broadly categorized into three types:\n",
        "    Supervised Learning: Trains models on labeled data to predict or classify new, unseen data.\n",
        "    Unsupervised Learning: Finds patterns or groups in unlabeled data, like clustering or dimensionality reduction.\n",
        "    Reinforcement Learning: Learns through trial and error to maximize rewards, ideal for decision-making tasks.\"\"\"\n",
        "    print(detect(input_text))\n",
        "\n",
        "    # Example: Process a PDF file\n",
        "    pdf_text = extract_text_from_pdf(\"example.pdf\")\n",
        "    print(detect(pdf_text))\n",
        "\n",
        "    # Example: Process an image file\n",
        "    image_text = extract_text_from_image(\"example_image.png\")\n",
        "    print(detect(image_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mFYLAOQFwxoE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}