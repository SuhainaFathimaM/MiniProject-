{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h--D4HgcoE_A",
        "outputId": "1829ba93-6e07-4a44-c784-49f9cde0a0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plagiarism Detected\n",
            "Plagiarism Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "import pickle\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load pre-trained model and vectorizer\n",
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "tfidf_vectorizer = pickle.load(open('tfidf_vectorizer.pkl', 'rb'))\n",
        "\n",
        "# Preprocess text (cleaning function)\n",
        "def preprocess_text(text):\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    stop_words = set(stopwords.words(\"english\"))  # Load stopwords\n",
        "    text = \" \".join(word for word in text.split() if word not in stop_words)  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "# Function to split large text into smaller chunks\n",
        "def split_text(text, chunk_size=50):\n",
        "    words = text.split()\n",
        "    chunks = [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Function to detect plagiarism for long texts\n",
        "def detect_large_text(input_text, similarity_threshold=0.7):\n",
        "    chunks = split_text(input_text)  # Split large text into smaller chunks\n",
        "    processed_chunks = [preprocess_text(chunk) for chunk in chunks]  # Preprocess chunks\n",
        "    vectorized_chunks = tfidf_vectorizer.transform(processed_chunks)  # Convert to TF-IDF\n",
        "\n",
        "    predictions = model.predict(vectorized_chunks)  # Get model predictions\n",
        "\n",
        "    # Cosine similarity check\n",
        "    similarity_scores = cosine_similarity(vectorized_chunks, vectorized_chunks)\n",
        "    max_similarity = np.max(similarity_scores)\n",
        "\n",
        "    # If any chunk is plagiarized OR similarity is high, mark as plagiarism\n",
        "    if 1 in predictions or max_similarity > similarity_threshold:\n",
        "        return \"Plagiarism Detected\"\n",
        "    return \"No Plagiarism\"\n",
        "\n",
        "# Example 1: Large paragraph with potential plagiarism\n",
        "large_text = \"\"\"Albert Einstein developed the theory of relativity, which changed\n",
        "the way we understand space and time. His work had a profound impact on physics\n",
        "and reshaped scientific thought forever. His famous equation, E=mc^2, revolutionized energy calculations.\"\"\"\n",
        "\n",
        "print(detect_large_text(large_text))\n",
        "\n",
        "# Example 2: Unique content (should return \"No Plagiarism\")\n",
        "unique_text = \"\"\"The development of artificial intelligence has led to breakthroughs\n",
        "in various fields such as healthcare, finance, and automation. Researchers continue\n",
        "to explore AI's potential in solving real-world problems.\"\"\"\n",
        "\n",
        "print(detect_large_text(unique_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "large_text = \"\"\"A self-introduction is a brief speech or written statement where you introduce yourself to others.\n",
        "\"\"\"\n",
        "print(detect_large_text(large_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jj4glqMoZB3",
        "outputId": "33fedab8-8756-4d46-9e07-88774c1d0624"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plagiarism Detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MdhV_NHkp6Fj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}